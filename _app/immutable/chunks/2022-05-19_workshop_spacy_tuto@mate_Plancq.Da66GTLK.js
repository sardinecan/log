import{s as jn,n as yt}from"./scheduler.DaEglZbh.js";import{S as En,i as On,e as a,s as p,H as ce,c as l,k as i,f as o,a as de,l as ke,d as t,m as me,g as s}from"./index.B_-7WD2a.js";function In(Pn){let u,ht="Tuto@mate - de l’utilisation de spaCy, comment parser un texte avec une bibliothèque Python",xe,r,qt="Ressources",ve,c,Pt='<li><a href="https://github.com/clement-plancq/tuto-mate" rel="nofollow">Notebook du tuto@mate</a> pour tester le code sans installer Python et spaCy (cliquer sur launch binder dans le README.md)</li> <li><a href="https://course.spacy.io/fr/" rel="nofollow">Cours par Ines Montani</a></li>',fe,d,Lt="Introduction",Ce,k,wt="SpaCy est un librairie Python pour le TAL, developpée par Matthew Honnibal et Ines Montani. C’est une bibliothèque Python pour le traitement des TAL sous licence libre (MIT 2.0), bien que distribuer par une société privée. En revanche les modèles sont distribués sous divers licences ouvertes (liées aux documents qui ont permis leur élaboration).",be,m,Tt="SpaCy est destiné à êter utilisé en production : donc traitement rapide, stable, qualité du code (test, documentation, etc.). Mais pas de chois dans le méthode ou l’algorithme utilisé. On sait ce qui est utilisé, c’est documenté, mais on ne peut pas modifier ces paramètres.",_e,x,Ht="Peut faire :",ye,v,Mt="<li>tokenisation</li> <li>étiquetage POS (verbe, nom, etc.)</li> <li>analyse syntaxique</li> <li>detection d’entités nommées</li> <li>lemmatisation</li> <li>catégorisation de texte</li> <li>word embedding</li>",he,f,jt="SpaCy utilise des modèles statistique (méthode neuronales).",qe,C,Et="Intérêts : c’est dy Python (wrapper R également), simple à prendre en main, très bien documenté (doc, tuto, etc.), grosse communauté sur github, fournit les méthodes et les moyens d’adapter le traitement et ou le modèle à des besoins particuliers ! Mais ce n’est pas forcément l’outils qui sera le meilleurs pour le français dans toutes les tâches de TAL.",Pe,b,Ot="Il existe d’autre frameworks pour le TAL",Le,_,It="<li>NLKT : python, orienté pédagogie, chois des méthodes et algos à utiliser</li> <li>CoreNLP : java, framework de Stanford, orienté recherche, chaîne de TAL la plus complète pour l’anglais</li> <li>Stanza : python, framework de Stanford également, modèle neuronaux entraînés sur les données d’Universal Dependancies (il y a un module spacy-stanza pour utiliser les modèles de Stanza</li> <li>Flair : python, framewok de Zalando (site de e-commerce), peut être le plus performant sur la reconnaissance d’entités nommées</li>",we,y,Nt=`Les modèles de spaCy
SpaCy utilise des modèles statistiques qui permettent de prédire des annotations linguistiques (identifier un verbe, un nom, le sentiment d’une phrase).
21 langues prise en compte. La qualité des résultats dépend beaucoup du corpus sur lequel s’est entraîné le modèle.
Pour le français, il y a 3 modèles + 1. Il sont tous issus du corpus <a href="http://www.linguist.univ-paris-diderot.fr/~mcandito/Publications/candito-seddah-taln2012.pdf" rel="nofollow">Sequoia</a> (wikipedia + presse (Est-républicain) + Agence euro du médicament, Europarl) et WikiNer, sauf le modèle trf, qui est issu de camembert-base (modèle Bert), distribué par Hugginf Face, entraîné sur Oscar.`,Te,h,Rt="Le choix du modèle est vraiment primordial pour les traitements.",He,q,At="Étape de la chaîne de traitement",Me,P,St="Tokenisation",je,L,Ut="Opération qui consiste à découper un texte ou chaîne de caractères en token. En linguistique il n’y a pas de définition précise de « mot », on parle alors de token. Les signes de ponctuation sont tokénisés.",Ee,w,zt="L’intérêt de spaCy, c’est que sa tokénisation n’est pas destructive. On peut donc, à partir de la tokenisation, reformer le texte (conservation des espaces par exemple).",Oe,T,Dt="Il est possible de modifier la tokenisation par défaut.",Ie,H,Bt="Concernant la tokénisation, SpaCy permet aussi de récupérer des groupes nominaux. Il est également possible de récupérer les phrases d’un texte.",Ne,M,Kt="Étiquetage (tagging)",Re,j,gt="Étape qui permet, pour chaque token de déterminer s’il s’agit d’un verbe, du adjectif, d’un nom, etc.",Ae,E,Se,Ln=`<code class="language-python">doc <span class="token operator">=</span> nlp<span class="token punctuation">(</span><span class="token string">"Tous mes beaux châteaux d'Équateur s'écroulent."</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> tok <span class="token keyword">in</span> doc<span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>tok<span class="token punctuation">,</span> tok<span class="token punctuation">.</span>pos_<span class="token punctuation">)</span></code>`,Ue,O,Qt=`<p>Tous ADJ
mes DET
beaux ADJ
châteaux NOUN
d’ ADP
Équateur PROPN
s’ PRON
écroulent VERB
. PUNCT</p>`,ze,I,Ft="Les annotation portant sur les token sont accessibles via les attributs des objets de type token",De,N,Jt="<li>pos_ contient l’étiquette de partie du discours de universal dependancies</li> <li>tag_ contient l’étiquette du corpus original, parfois plus détaillée</li> <li>lemma_ pour le lemme</li> <li>morph pour l’analyse morphologique</li>",Be,R,Ke,wn=`<code class="language-python"><span class="token keyword">for</span> token <span class="token keyword">in</span> doc<span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>token<span class="token punctuation">,</span> token<span class="token punctuation">.</span>lemma_<span class="token punctuation">,</span> token<span class="token punctuation">.</span>pos_<span class="token punctuation">,</span> token<span class="token punctuation">.</span>morph<span class="token punctuation">)</span></code>`,ge,A,Vt=`<p>Tous tout ADJ Gender=Masc|Number=Plur
mes mon DET Number=Plur|Poss=Yes
beaux beal ADJ Gender=Masc|Number=Plur
châteaux château NOUN Gender=Masc|Number=Plur
d’ de ADP
Équateur Équateur PROPN
s’ se PRON Person=3|Reflex=Yes
écroulent écrouler VERB Mood=Ind|Number=Plur|Person=3|Tense=Pres|VerbForm=Fin
. . PUNCT</p>`,Qe,S,Xt="Détection d’entités nommées (ner)",Fe,U,Gt="Pour repérer les noms de personnes, de lieux, d’organisation, miscelannée et parfois même les dates.",Je,z,Wt="Il y a également dans spaCy un visualiseur, qui permet d’avoir une représentation visuel du traitement du texte en html.",Ve,D,Yt="Il est possible d’adapter la reconnaissance des entités nommées, voire même d’entrainer d’autres modèles.",Xe,B,Zt="Analyse syntaxique (parsing)",Ge,K,$t="C’est une analyse en dépendance avec spaCy. Dans ce type d’analyse, chaque mot d’une phrase à un gouverneur unique (head), la relation de dépendance entre le mot et son gouverneur est typée (nsubj, obj, etc.) Pour la tête de la phrase on utilise la relation ROOT.",We,g,en=`La structure produite par l’analyse syntaxique est un arbre, un graphe acyclique et connexe.
Les tokens sont les nœuds, les arcs sont les dépendances, le type de la relation est l’étiquette de l’arc.`,Ye,Q,Ze,Tn=`<code class="language-python">doc <span class="token operator">=</span> nlp<span class="token punctuation">(</span><span class="token string">"Il te refile en stéréo la chanson des sirènes."</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> token <span class="token keyword">in</span> doc<span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>token<span class="token punctuation">,</span> token<span class="token punctuation">.</span>dep_<span class="token punctuation">,</span> token<span class="token punctuation">.</span>head<span class="token punctuation">)</span></code>`,$e,F,tn=`<p>Il expl:subj refile
te iobj refile
refile ROOT refile
en case stéréo
stéréo obl:arg refile
la det chanson
chanson obj refile
des case sirènes
sirènes nmod chanson
. punct refile</p>`,et,J,nn="Il existe aussi une représentation graphique de la dépendance des tokens entre eux.",tt,V,sn="Dans l’analyse en dépendance on peut aussi parcourir l’arbre de dépendance. Les attributs de token suivant peuvent être utilisés pour parcourir l’arbre de dépendance :",nt,X,an="<li><code>children</code> les tokens dépendants du token</li> <li><code>subtree</code> tous les descendants du token</li> <li><code>ancestors</code> tous les parents du token</li> <li><code>rights</code> les enfants à droite du token</li> <li><code>lefts</code> les enfants à gauche du token</li>",st,G,at,Hn=`<code class="language-python">root <span class="token operator">=</span> <span class="token punctuation">[</span>token <span class="token keyword">for</span> token <span class="token keyword">in</span> doc <span class="token keyword">if</span> token<span class="token punctuation">.</span>head <span class="token operator">==</span> token<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
subjects <span class="token operator">=</span> <span class="token punctuation">[</span>tok <span class="token keyword">for</span> tok <span class="token keyword">in</span> root<span class="token punctuation">.</span>lefts <span class="token keyword">if</span> <span class="token string">"subj"</span> <span class="token keyword">in</span> tok<span class="token punctuation">.</span>dep_<span class="token punctuation">]</span>
subject <span class="token operator">=</span> subjects<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
objs <span class="token operator">=</span> <span class="token punctuation">[</span>tok <span class="token keyword">for</span> tok <span class="token keyword">in</span> root<span class="token punctuation">.</span>rights <span class="token keyword">if</span> tok<span class="token punctuation">.</span>dep_ <span class="token operator">==</span> <span class="token string">"obj"</span><span class="token punctuation">]</span>
obj <span class="token operator">=</span> objs<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"sujet : </span><span class="token interpolation"><span class="token punctuation">&#123;</span>subject<span class="token punctuation">&#125;</span></span><span class="token string">, prédicat : </span><span class="token interpolation"><span class="token punctuation">&#123;</span>root<span class="token punctuation">&#125;</span></span><span class="token string">, objet : </span><span class="token interpolation"><span class="token punctuation">&#123;</span>obj<span class="token punctuation">&#125;</span></span><span class="token string">"</span></span><span class="token punctuation">)</span></code>`,lt,W,ln="<p>sujet : Il, prédicat : refile, objet : chanson</p>",pt,Y,pn="Extraction d’information",ot,Z,on=`À partir de tous ces traitements, il est possible d’effectuer d’autres opérations.
Spacy a une classe Matcher qui permet de repérer des tokens ou des séquences de tokens à l’aide de patrons (pattern).
Ces patrons peuvent porter sur la forme des tokens ou leurs attributs (pos, ent, …).
On peut aussi utiliser des catégories comme IS_ALPHA ou IS_NUM, voir la doc
(Il existe une démo avec interface graphique mais pas pour le français 🙁)`,it,$,ut,Mn=`<code class="language-python"><span class="token keyword">from</span> spacy<span class="token punctuation">.</span>matcher <span class="token keyword">import</span> Matcher
doc <span class="token operator">=</span> nlp<span class="token punctuation">(</span><span class="token string">"Ce modèle est aussi disponible en taille XL ; je vous le conseille."</span><span class="token punctuation">)</span>
matcher <span class="token operator">=</span> Matcher<span class="token punctuation">(</span>nlp<span class="token punctuation">.</span>vocab<span class="token punctuation">)</span>

pattern <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">&#123;</span><span class="token string">"LOWER"</span><span class="token punctuation">:</span> <span class="token string">"en"</span><span class="token punctuation">&#125;</span><span class="token punctuation">,</span> <span class="token punctuation">&#123;</span><span class="token string">"LOWER"</span><span class="token punctuation">:</span> <span class="token string">"taille"</span><span class="token punctuation">&#125;</span><span class="token punctuation">,</span> <span class="token punctuation">&#123;</span><span class="token string">"IS_ALPHA"</span><span class="token punctuation">:</span> <span class="token boolean">True</span><span class="token punctuation">,</span> <span class="token string">"IS_UPPER"</span><span class="token punctuation">:</span> <span class="token boolean">True</span><span class="token punctuation">&#125;</span><span class="token punctuation">]</span>
<span class="token comment">#pattern : 'en' + 'taille' + lettres en maj</span>

matcher<span class="token punctuation">.</span>add<span class="token punctuation">(</span><span class="token string">"tailles"</span><span class="token punctuation">,</span> <span class="token punctuation">[</span>pattern<span class="token punctuation">]</span><span class="token punctuation">)</span>
matches <span class="token operator">=</span> matcher<span class="token punctuation">(</span>doc<span class="token punctuation">)</span>
<span class="token keyword">for</span> _<span class="token punctuation">,</span> start<span class="token punctuation">,</span> end <span class="token keyword">in</span> matches<span class="token punctuation">:</span>
    span <span class="token operator">=</span> doc<span class="token punctuation">[</span>start<span class="token punctuation">:</span>end<span class="token punctuation">]</span>  <span class="token comment"># The matched span</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"</span><span class="token interpolation"><span class="token punctuation">&#123;</span>span<span class="token punctuation">.</span>text<span class="token punctuation">&#125;</span></span><span class="token string"> (</span><span class="token interpolation"><span class="token punctuation">&#123;</span>start<span class="token punctuation">&#125;</span></span><span class="token string">, </span><span class="token interpolation"><span class="token punctuation">&#123;</span>end<span class="token punctuation">&#125;</span></span><span class="token string">)"</span></span><span class="token punctuation">)</span></code>`,rt,ee,un="<p>en taille XL (5, 8)</p>",ct,te,rn="Ça fonctionne pour les séquences comme « en taille M » ou « en taille XL » mais pas pour « vous l’avez en XL ? »",dt,ne,cn="C’est un patron de repérage de séquences de mots. Il est possible de rechercher aussi des regEx.",kt,se,dn="Pour les entités nommées, parfois ça fonctionne mal avec le français (prénoms mal étiqueté, comme misc par exemple), il est donc possible de travailler avec des patrons pour correctement étiqueter les entités nommées, à partir d’un liste de noms par exemple.",mt,ae,kn=`Depuis la v3 de spaCy, il y a un nouvel outil, Dependency Matcher qui permet de faire de l’extraction de patrons syntaxiques. On peut faire porter les requêtes sur l’arbre syntaxique et non plus seulement sur la séquence des tokens.
Permet aussi de tirer des informations sur un texte, à partir de pattern précis
Par exemple récupérer tous tokens qui sont les lemmes de « acheter » ou « vendre », puis d’analyser les dépendances de ces tokens pour extraite, par exemple, le sujet et l’objet.`,xt,le,mn="Une critique, c’est que spaCy ne prend pas le format sql (pris en charge par txm par exemple).",vt,pe,xn="Adaptation du modèle",ft,oe,vn="L’exemple des entités nommées",Ct,ie,fn=`La taille et la nature du corpus d’entraînement seront déterminantes. Il est possible d’amender un modèle existant avec un jeu de données annotées de taille réduite.
Exemple sur les entités nommées mais la procèdure d’entraînement fonctionne pour d’autres niveaux d’annotations (pos, dépendance)
Voir la <a href="https://spacy.io/usage/training" rel="nofollow">doc</a>.`,bt,ue,Cn="SpaCy propose aussi des outils pour évaluer les performance des modèles que l’on a généré, ainsi que des mécanismes d’export et d’import des modèles et des données.",_t,re,bn="Il ne faut pas avoir peur de faire son propre modèle, pour le traitement d’un corpus spécifique, ce n’est pas forcément très long à faire.";return{c(){u=a("h1"),u.textContent=ht,xe=p(),r=a("h2"),r.textContent=qt,ve=p(),c=a("ul"),c.innerHTML=Pt,fe=p(),d=a("h2"),d.textContent=Lt,Ce=p(),k=a("p"),k.textContent=wt,be=p(),m=a("p"),m.textContent=Tt,_e=p(),x=a("p"),x.textContent=Ht,ye=p(),v=a("ul"),v.innerHTML=Mt,he=p(),f=a("p"),f.textContent=jt,qe=p(),C=a("p"),C.textContent=Et,Pe=p(),b=a("p"),b.textContent=Ot,Le=p(),_=a("ul"),_.innerHTML=It,we=p(),y=a("p"),y.innerHTML=Nt,Te=p(),h=a("p"),h.textContent=Rt,He=p(),q=a("h2"),q.textContent=At,Me=p(),P=a("h3"),P.textContent=St,je=p(),L=a("p"),L.textContent=Ut,Ee=p(),w=a("p"),w.textContent=zt,Oe=p(),T=a("p"),T.textContent=Dt,Ie=p(),H=a("p"),H.textContent=Bt,Ne=p(),M=a("h3"),M.textContent=Kt,Re=p(),j=a("p"),j.textContent=gt,Ae=p(),E=a("pre"),Se=new ce(!1),Ue=p(),O=a("blockquote"),O.innerHTML=Qt,ze=p(),I=a("p"),I.textContent=Ft,De=p(),N=a("ul"),N.innerHTML=Jt,Be=p(),R=a("pre"),Ke=new ce(!1),ge=p(),A=a("blockquote"),A.innerHTML=Vt,Qe=p(),S=a("h3"),S.textContent=Xt,Fe=p(),U=a("p"),U.textContent=Gt,Je=p(),z=a("p"),z.textContent=Wt,Ve=p(),D=a("p"),D.textContent=Yt,Xe=p(),B=a("h3"),B.textContent=Zt,Ge=p(),K=a("p"),K.textContent=$t,We=p(),g=a("p"),g.textContent=en,Ye=p(),Q=a("pre"),Ze=new ce(!1),$e=p(),F=a("blockquote"),F.innerHTML=tn,et=p(),J=a("p"),J.textContent=nn,tt=p(),V=a("p"),V.textContent=sn,nt=p(),X=a("ul"),X.innerHTML=an,st=p(),G=a("pre"),at=new ce(!1),lt=p(),W=a("blockquote"),W.innerHTML=ln,pt=p(),Y=a("h2"),Y.textContent=pn,ot=p(),Z=a("p"),Z.textContent=on,it=p(),$=a("pre"),ut=new ce(!1),rt=p(),ee=a("blockquote"),ee.innerHTML=un,ct=p(),te=a("p"),te.textContent=rn,dt=p(),ne=a("p"),ne.textContent=cn,kt=p(),se=a("p"),se.textContent=dn,mt=p(),ae=a("p"),ae.textContent=kn,xt=p(),le=a("p"),le.textContent=mn,vt=p(),pe=a("h2"),pe.textContent=xn,ft=p(),oe=a("h3"),oe.textContent=vn,Ct=p(),ie=a("p"),ie.innerHTML=fn,bt=p(),ue=a("p"),ue.textContent=Cn,_t=p(),re=a("p"),re.textContent=bn,this.h()},l(e){u=l(e,"H1",{"data-svelte-h":!0}),i(u)!=="svelte-1nkrmnk"&&(u.textContent=ht),xe=o(e),r=l(e,"H2",{"data-svelte-h":!0}),i(r)!=="svelte-g1gtei"&&(r.textContent=qt),ve=o(e),c=l(e,"UL",{"data-svelte-h":!0}),i(c)!=="svelte-1sfcbuq"&&(c.innerHTML=Pt),fe=o(e),d=l(e,"H2",{"data-svelte-h":!0}),i(d)!=="svelte-1ukekoe"&&(d.textContent=Lt),Ce=o(e),k=l(e,"P",{"data-svelte-h":!0}),i(k)!=="svelte-fogvb4"&&(k.textContent=wt),be=o(e),m=l(e,"P",{"data-svelte-h":!0}),i(m)!=="svelte-16fvfzc"&&(m.textContent=Tt),_e=o(e),x=l(e,"P",{"data-svelte-h":!0}),i(x)!=="svelte-ee7zx7"&&(x.textContent=Ht),ye=o(e),v=l(e,"UL",{"data-svelte-h":!0}),i(v)!=="svelte-89vpcj"&&(v.innerHTML=Mt),he=o(e),f=l(e,"P",{"data-svelte-h":!0}),i(f)!=="svelte-1yb6fsm"&&(f.textContent=jt),qe=o(e),C=l(e,"P",{"data-svelte-h":!0}),i(C)!=="svelte-1m60cbj"&&(C.textContent=Et),Pe=o(e),b=l(e,"P",{"data-svelte-h":!0}),i(b)!=="svelte-dtqr8k"&&(b.textContent=Ot),Le=o(e),_=l(e,"UL",{"data-svelte-h":!0}),i(_)!=="svelte-1xjs1zc"&&(_.innerHTML=It),we=o(e),y=l(e,"P",{"data-svelte-h":!0}),i(y)!=="svelte-169phrd"&&(y.innerHTML=Nt),Te=o(e),h=l(e,"P",{"data-svelte-h":!0}),i(h)!=="svelte-xt0p3n"&&(h.textContent=Rt),He=o(e),q=l(e,"H2",{"data-svelte-h":!0}),i(q)!=="svelte-1l3kxey"&&(q.textContent=At),Me=o(e),P=l(e,"H3",{"data-svelte-h":!0}),i(P)!=="svelte-ayx0qe"&&(P.textContent=St),je=o(e),L=l(e,"P",{"data-svelte-h":!0}),i(L)!=="svelte-188d52t"&&(L.textContent=Ut),Ee=o(e),w=l(e,"P",{"data-svelte-h":!0}),i(w)!=="svelte-twcz49"&&(w.textContent=zt),Oe=o(e),T=l(e,"P",{"data-svelte-h":!0}),i(T)!=="svelte-1r7hqkf"&&(T.textContent=Dt),Ie=o(e),H=l(e,"P",{"data-svelte-h":!0}),i(H)!=="svelte-zt8fsk"&&(H.textContent=Bt),Ne=o(e),M=l(e,"H3",{"data-svelte-h":!0}),i(M)!=="svelte-9tk5gg"&&(M.textContent=Kt),Re=o(e),j=l(e,"P",{"data-svelte-h":!0}),i(j)!=="svelte-1n1zpla"&&(j.textContent=gt),Ae=o(e),E=l(e,"PRE",{class:!0});var n=de(E);Se=ke(n,!1),n.forEach(t),Ue=o(e),O=l(e,"BLOCKQUOTE",{"data-svelte-h":!0}),i(O)!=="svelte-kzzplv"&&(O.innerHTML=Qt),ze=o(e),I=l(e,"P",{"data-svelte-h":!0}),i(I)!=="svelte-yv1kd0"&&(I.textContent=Ft),De=o(e),N=l(e,"UL",{"data-svelte-h":!0}),i(N)!=="svelte-vocjgu"&&(N.innerHTML=Jt),Be=o(e),R=l(e,"PRE",{class:!0});var _n=de(R);Ke=ke(_n,!1),_n.forEach(t),ge=o(e),A=l(e,"BLOCKQUOTE",{"data-svelte-h":!0}),i(A)!=="svelte-12j9sc5"&&(A.innerHTML=Vt),Qe=o(e),S=l(e,"H3",{"data-svelte-h":!0}),i(S)!=="svelte-11hjjw4"&&(S.textContent=Xt),Fe=o(e),U=l(e,"P",{"data-svelte-h":!0}),i(U)!=="svelte-37r4y2"&&(U.textContent=Gt),Je=o(e),z=l(e,"P",{"data-svelte-h":!0}),i(z)!=="svelte-8tedxk"&&(z.textContent=Wt),Ve=o(e),D=l(e,"P",{"data-svelte-h":!0}),i(D)!=="svelte-1cbgjnp"&&(D.textContent=Yt),Xe=o(e),B=l(e,"H3",{"data-svelte-h":!0}),i(B)!=="svelte-19wnw9b"&&(B.textContent=Zt),Ge=o(e),K=l(e,"P",{"data-svelte-h":!0}),i(K)!=="svelte-1ect0ua"&&(K.textContent=$t),We=o(e),g=l(e,"P",{"data-svelte-h":!0}),i(g)!=="svelte-1fcas5u"&&(g.textContent=en),Ye=o(e),Q=l(e,"PRE",{class:!0});var yn=de(Q);Ze=ke(yn,!1),yn.forEach(t),$e=o(e),F=l(e,"BLOCKQUOTE",{"data-svelte-h":!0}),i(F)!=="svelte-jsh8p4"&&(F.innerHTML=tn),et=o(e),J=l(e,"P",{"data-svelte-h":!0}),i(J)!=="svelte-1crldaq"&&(J.textContent=nn),tt=o(e),V=l(e,"P",{"data-svelte-h":!0}),i(V)!=="svelte-k338ro"&&(V.textContent=sn),nt=o(e),X=l(e,"UL",{"data-svelte-h":!0}),i(X)!=="svelte-1cogdop"&&(X.innerHTML=an),st=o(e),G=l(e,"PRE",{class:!0});var hn=de(G);at=ke(hn,!1),hn.forEach(t),lt=o(e),W=l(e,"BLOCKQUOTE",{"data-svelte-h":!0}),i(W)!=="svelte-11hdil2"&&(W.innerHTML=ln),pt=o(e),Y=l(e,"H2",{"data-svelte-h":!0}),i(Y)!=="svelte-1l8s3lo"&&(Y.textContent=pn),ot=o(e),Z=l(e,"P",{"data-svelte-h":!0}),i(Z)!=="svelte-didik0"&&(Z.textContent=on),it=o(e),$=l(e,"PRE",{class:!0});var qn=de($);ut=ke(qn,!1),qn.forEach(t),rt=o(e),ee=l(e,"BLOCKQUOTE",{"data-svelte-h":!0}),i(ee)!=="svelte-1gl5z27"&&(ee.innerHTML=un),ct=o(e),te=l(e,"P",{"data-svelte-h":!0}),i(te)!=="svelte-7o74nv"&&(te.textContent=rn),dt=o(e),ne=l(e,"P",{"data-svelte-h":!0}),i(ne)!=="svelte-g325eo"&&(ne.textContent=cn),kt=o(e),se=l(e,"P",{"data-svelte-h":!0}),i(se)!=="svelte-1bgnoir"&&(se.textContent=dn),mt=o(e),ae=l(e,"P",{"data-svelte-h":!0}),i(ae)!=="svelte-zz27la"&&(ae.textContent=kn),xt=o(e),le=l(e,"P",{"data-svelte-h":!0}),i(le)!=="svelte-175sjvu"&&(le.textContent=mn),vt=o(e),pe=l(e,"H2",{"data-svelte-h":!0}),i(pe)!=="svelte-1w26jsl"&&(pe.textContent=xn),ft=o(e),oe=l(e,"H3",{"data-svelte-h":!0}),i(oe)!=="svelte-1sob5kz"&&(oe.textContent=vn),Ct=o(e),ie=l(e,"P",{"data-svelte-h":!0}),i(ie)!=="svelte-j69u7p"&&(ie.innerHTML=fn),bt=o(e),ue=l(e,"P",{"data-svelte-h":!0}),i(ue)!=="svelte-plu7oa"&&(ue.textContent=Cn),_t=o(e),re=l(e,"P",{"data-svelte-h":!0}),i(re)!=="svelte-1rz72dk"&&(re.textContent=bn),this.h()},h(){Se.a=null,me(E,"class","language-python"),Ke.a=null,me(R,"class","language-python"),Ze.a=null,me(Q,"class","language-python"),at.a=null,me(G,"class","language-python"),ut.a=null,me($,"class","language-python")},m(e,n){s(e,u,n),s(e,xe,n),s(e,r,n),s(e,ve,n),s(e,c,n),s(e,fe,n),s(e,d,n),s(e,Ce,n),s(e,k,n),s(e,be,n),s(e,m,n),s(e,_e,n),s(e,x,n),s(e,ye,n),s(e,v,n),s(e,he,n),s(e,f,n),s(e,qe,n),s(e,C,n),s(e,Pe,n),s(e,b,n),s(e,Le,n),s(e,_,n),s(e,we,n),s(e,y,n),s(e,Te,n),s(e,h,n),s(e,He,n),s(e,q,n),s(e,Me,n),s(e,P,n),s(e,je,n),s(e,L,n),s(e,Ee,n),s(e,w,n),s(e,Oe,n),s(e,T,n),s(e,Ie,n),s(e,H,n),s(e,Ne,n),s(e,M,n),s(e,Re,n),s(e,j,n),s(e,Ae,n),s(e,E,n),Se.m(Ln,E),s(e,Ue,n),s(e,O,n),s(e,ze,n),s(e,I,n),s(e,De,n),s(e,N,n),s(e,Be,n),s(e,R,n),Ke.m(wn,R),s(e,ge,n),s(e,A,n),s(e,Qe,n),s(e,S,n),s(e,Fe,n),s(e,U,n),s(e,Je,n),s(e,z,n),s(e,Ve,n),s(e,D,n),s(e,Xe,n),s(e,B,n),s(e,Ge,n),s(e,K,n),s(e,We,n),s(e,g,n),s(e,Ye,n),s(e,Q,n),Ze.m(Tn,Q),s(e,$e,n),s(e,F,n),s(e,et,n),s(e,J,n),s(e,tt,n),s(e,V,n),s(e,nt,n),s(e,X,n),s(e,st,n),s(e,G,n),at.m(Hn,G),s(e,lt,n),s(e,W,n),s(e,pt,n),s(e,Y,n),s(e,ot,n),s(e,Z,n),s(e,it,n),s(e,$,n),ut.m(Mn,$),s(e,rt,n),s(e,ee,n),s(e,ct,n),s(e,te,n),s(e,dt,n),s(e,ne,n),s(e,kt,n),s(e,se,n),s(e,mt,n),s(e,ae,n),s(e,xt,n),s(e,le,n),s(e,vt,n),s(e,pe,n),s(e,ft,n),s(e,oe,n),s(e,Ct,n),s(e,ie,n),s(e,bt,n),s(e,ue,n),s(e,_t,n),s(e,re,n)},p:yt,i:yt,o:yt,d(e){e&&(t(u),t(xe),t(r),t(ve),t(c),t(fe),t(d),t(Ce),t(k),t(be),t(m),t(_e),t(x),t(ye),t(v),t(he),t(f),t(qe),t(C),t(Pe),t(b),t(Le),t(_),t(we),t(y),t(Te),t(h),t(He),t(q),t(Me),t(P),t(je),t(L),t(Ee),t(w),t(Oe),t(T),t(Ie),t(H),t(Ne),t(M),t(Re),t(j),t(Ae),t(E),t(Ue),t(O),t(ze),t(I),t(De),t(N),t(Be),t(R),t(ge),t(A),t(Qe),t(S),t(Fe),t(U),t(Je),t(z),t(Ve),t(D),t(Xe),t(B),t(Ge),t(K),t(We),t(g),t(Ye),t(Q),t($e),t(F),t(et),t(J),t(tt),t(V),t(nt),t(X),t(st),t(G),t(lt),t(W),t(pt),t(Y),t(ot),t(Z),t(it),t($),t(rt),t(ee),t(ct),t(te),t(dt),t(ne),t(kt),t(se),t(mt),t(ae),t(xt),t(le),t(vt),t(pe),t(ft),t(oe),t(Ct),t(ie),t(bt),t(ue),t(_t),t(re))}}}const An={title:"Tuto@mate - de l’utilisation de spaCy, comment parser un texte avec une bibliothèque Python",date:"2022-05-19",speaker:"Clément Plancq",category:"workshop",keywords:""};class Sn extends En{constructor(u){super(),On(this,u,null,In,jn,{})}}export{Sn as default,An as metadata};
